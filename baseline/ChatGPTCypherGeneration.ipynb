{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.54.5-py3-none-any.whl (389 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\chao\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\chao\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.7.1-cp310-none-win_amd64.whl (201 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\chao\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\chao\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\chao\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\chao\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: sniffio, h11, pydantic-core, httpcore, anyio, annotated-types, pydantic, jiter, httpx, distro, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 jiter-0.7.1 openai-1.54.5 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\chao\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, nodes, instances):\n",
    "    \"\"\"Build and format the prompt.\"\"\"\n",
    "    formatted_prompt = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"You are an experienced Cypher developer to convert natural language questions to Cypher queries!\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": f\"\"\"\n",
    "        Convert the natural language question into Cypher query language, please only output the Cypher.\n",
    "        ###Question: {question}, Nodes: {nodes}, Instances: {instances}\"\"\"\n",
    "        \"\"\"\n",
    "        ###Here is the graph schema:\n",
    "        Node properties are the following:\n",
    "        MolecularFunction {url: STRING, license: STRING, name: STRING, identifier: STRING, source: STRING},\n",
    "        Pathway {license: STRING, source: STRING, identifier: STRING, name: STRING, url: STRING},\n",
    "        Anatomy {license: STRING, mesh_id: STRING, source: STRING, url: STRING, name: STRING, identifier: STRING, bto_id: STRING},\n",
    "        PharmacologicClass {class_type: STRING, license: STRING, source: STRING, url: STRING, identifier: STRING, name: STRING},\n",
    "        Gene {license: STRING, chromosome: STRING, url: STRING, source: STRING, description: STRING, identifier: INTEGER, name: STRING},\n",
    "        Symptom {license: STRING, name: STRING, source: STRING, identifier: STRING, url: STRING},\n",
    "        BiologicalProcess {license: STRING, source: STRING, url: STRING, identifier: STRING, name: STRING},\n",
    "        Disease {license: STRING, source: STRING, url: STRING, identifier: STRING, name: STRING},\n",
    "        Compound {license: STRING, inchi: STRING, inchikey: STRING, source: STRING, url: STRING, identifier: STRING, name: STRING},\n",
    "        CellularComponent {license: STRING, name: STRING, url: STRING, identifier: STRING, source: STRING},\n",
    "        SideEffect {license: STRING, source: STRING, url: STRING, name: STRING, identifier: STRING}\n",
    "        ###The relationships are the following:\n",
    "        (:Anatomy)-[:EXPRESSES_AeG]->(:Gene),\n",
    "        (:Anatomy)-[:DOWNREGULATES_AdG]->(:Gene),\n",
    "        (:Anatomy)-[:UPREGULATES_AuG]->(:Gene),\n",
    "        (:PharmacologicClass)-[:INCLUDES_PCiC]->(:Compound),\n",
    "        (:Gene)-[:PARTICIPATES_GpMF]->(:MolecularFunction),\n",
    "        (:Gene)-[:PARTICIPATES_GpBP]->(:BiologicalProcess),\n",
    "        (:Gene)-[:COVARIES_GcG]->(:Gene),\n",
    "        (:Gene)-[:REGULATES_GrG]->(:Gene),\n",
    "        (:Gene)-[:INTERACTS_GiG]->(:Gene),\n",
    "        (:Gene)-[:PARTICIPATES_GpPW]->(:Pathway),\n",
    "        (:Gene)-[:PARTICIPATES_GpCC]->(:CellularComponent),\n",
    "        (:Disease)-[:LOCALIZES_DlA]->(:Anatomy),\n",
    "        (:Disease)-[:ASSOCIATES_DaG]->(:Gene),\n",
    "        (:Disease)-[:PRESENTS_DpS]->(:Symptom),\n",
    "        (:Disease)-[:RESEMBLES_DrD]->(:Disease),\n",
    "        (:Disease)-[:DOWNREGULATES_DdG]->(:Gene),\n",
    "        (:Disease)-[:UPREGULATES_DuG]->(:Gene),\n",
    "        (:Compound)-[:UPREGULATES_CuG]->(:Gene),\n",
    "        (:Compound)-[:DOWNREGULATES_CdG]->(:Gene),\n",
    "        (:Compound)-[:BINDS_CbG]->(:Gene),\n",
    "        (:Compound)-[:CAUSES_CcSE]->(:SideEffect),\n",
    "        (:Compound)-[:RESEMBLES_CrC]->(:Compound),\n",
    "        (:Compound)-[:TREATS_CtD]->(:Disease),\n",
    "        (:Compound)-[:PALLIATES_CpD]->(:Disease)\n",
    "        ###Please only output the Cypher\n",
    "        \"\"\"}]\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---- SAFETY: set OPENAI_API_KEY in your environment ----\n",
    "# Windows PowerShell:  setx OPENAI_API_KEY \"sk-....\"\n",
    "# Then restart terminal / IDE\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"\"),\n",
    ")\n",
    "\n",
    "\n",
    "def read_json(file_path: str) -> Any:\n",
    "    \"\"\"Reads a JSON file into a Python object.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        return json.load(fp)\n",
    "\n",
    "\n",
    "def write_json_safely(obj, path: str):\n",
    "    \"\"\"Write JSON with UTF-8 encoding and indentation.\"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def prompt_model(message):\n",
    "    \"\"\"Call the model and return text output.\"\"\"\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        max_completion_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        messages=message,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "\n",
    "def load_checkpoint(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Checkpoint stores processed outputs and error logs.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return read_json(path)\n",
    "    return {\"done\": {}, \"errors\": []}\n",
    "    # done: dict of {id: output_text}\n",
    "    # errors: list of dicts with diagnostics\n",
    "\n",
    "\n",
    "def save_checkpoint(path: str, ckpt: Dict[str, Any]):\n",
    "    write_json_safely(ckpt, path)\n",
    "\n",
    "\n",
    "def process_file_in_batches(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    checkpoint_path: str,\n",
    "    batch_size: int = 30,\n",
    "    sleep_s: float = 0.0,\n",
    "    id_key: str = \"id\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes instances in batches, saving after each batch.\n",
    "    - output_path: final enriched dataset\n",
    "    - checkpoint_path: incremental {done, errors} for resume\n",
    "    \"\"\"\n",
    "    data: List[Dict[str, Any]] = read_json(input_path)\n",
    "    ckpt = load_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Ensure each instance has a stable id for resume\n",
    "    for idx, inst in enumerate(data):\n",
    "        if id_key not in inst:\n",
    "            inst[id_key] = f\"{idx}\"  # stable as long as file order unchanged\n",
    "\n",
    "    total = len(data)\n",
    "    processed_now = 0\n",
    "\n",
    "    # Iterate in batches\n",
    "    for start in range(0, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        batch = data[start:end]\n",
    "\n",
    "        # Process each item in the batch\n",
    "        for inst in batch:\n",
    "            inst_id = str(inst[id_key])\n",
    "\n",
    "            # Skip if already done (resume)\n",
    "            if inst_id in ckpt[\"done\"]:\n",
    "                inst[\"GPT-5.1-Output\"] = ckpt[\"done\"][inst_id]\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Your create_prompt should return either a string or messages list\n",
    "                msg = create_prompt(inst[\"rewrite_nl\"], inst[\"nodes\"], inst[\"instance\"])\n",
    "                out = prompt_model(msg)\n",
    "\n",
    "                inst[\"GPT-5.1-Output\"] = out\n",
    "                ckpt[\"done\"][inst_id] = out\n",
    "                processed_now += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # Store error with context; keep running\n",
    "                err = {\n",
    "                    \"id\": inst_id,\n",
    "                    \"error\": repr(e),\n",
    "                    \"rewrite_nl\": inst.get(\"rewrite_nl\", None),\n",
    "                }\n",
    "                ckpt[\"errors\"].append(err)\n",
    "                inst[\"GPT-5.1-Output\"] = None\n",
    "                inst[\"GPT-5.1-Error\"] = repr(e)\n",
    "\n",
    "        # Save checkpoint and partial output after each batch\n",
    "        save_checkpoint(checkpoint_path, ckpt)\n",
    "        write_json_safely(data, output_path)\n",
    "\n",
    "        print(f\"[{os.path.basename(input_path)}] saved batch {start}-{end} / {total} \"\n",
    "              f\"(new processed this run: {processed_now}, total done: {len(ckpt['done'])}, errors: {len(ckpt['errors'])})\")\n",
    "\n",
    "        if sleep_s > 0:\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "\n",
    "# -------------------- RUN --------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
